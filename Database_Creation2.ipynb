{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "project-overview"
      },
      "source": [
        "# AI Interview Dataset Generator\n",
        "\n",
        "This notebook creates a synthetic dataset of mock interview conversations for various technical roles.\n",
        "\n",
        "## Features:\n",
        "- Generates 50 interview conversations per role\n",
        "- Includes greetings, questions, follow-ups, and feedback\n",
        "- Covers 10 different technical roles\n",
        "- Outputs in JSONL format for training AI models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup-section"
      },
      "source": [
        "## 1. Import Required Libraries\n",
        "\n",
        "We'll need these packages:\n",
        "- `json` for handling JSON data\n",
        "- `random` for selecting random elements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "import-libraries"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "data-definition"
      },
      "source": [
        "## 2. Define Dataset Components\n",
        "\n",
        "We'll create templates for different parts of the interview conversation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "define-components"
      },
      "outputs": [],
      "source": [
       
        "roles = [\n",
        "    \"Frontend Developer\", \"Backend Developer\", \"AI Engineer\", \"Cybersecurity Analyst\",\n",
        "    \"Cloud Architect\", \"DevOps Engineer\", \"Software Engineer\", \"UX Developer\",\n",
        "    \"Product Manager\", \"Data Scientist\"\n",
        "]\n",
        "\n",
       
        "greetings = [\n",
        "    \"Hello! I'm your AI interviewer for the {role} role. Shall we begin?\",\n",
        "    \"Hi there! Let's start your interview for the {role} position.\",\n",
        "    \"Welcome to your mock interview for {role}. Ready to dive in?\"\n",
        "]\n",
        "\n",
       
        "follow_ups = [\n",
        "    \"Interesting! Could you elaborate on that?\",\n",
        "    \"Good point. Would you add anything else?\",\n",
        "    \"Nice, but how would you handle edge cases?\",\n",
        "    \"What are the trade-offs of that approach?\"\n",
        "]\n",
        "\n",
        
        "feedbacks = [\n",
        "    \"That's a good answer! You covered the core concept.\",\n",
        "    \"Great explanation. Keep that confidence going.\",\n",
        "    \"Not bad, but you might want to clarify a bit more.\",\n",
        "    \"You're on the right track, just missing some detail.\"\n",
        "]\n",
        "\n",
       
        "closings = [\n",
        "    \"Thanks for your time. You did well!\",\n",
        "    \"That wraps up our session. Keep practicing!\",\n",
        "    \"Appreciate your effort today. Stay sharp!\"\n",
        "]\n",
        "\n",
        
        "sample_questions = {\n",
        "    \"Frontend Developer\": [\n",
        "        \"How do you ensure cross-browser compatibility?\",\n",
        "        \"What is the Virtual DOM and why is it useful?\",\n",
        "        \"When would you use a CSS preprocessor like SASS?\"\n",
        "    ],\n",
        "    \"Backend Developer\": [\n",
        "        \"What is the difference between REST and GraphQL?\",\n",
        "        \"How do you scale a backend application?\",\n",
        "        \"Explain how you would implement user authentication.\"\n",
        "    ],\n",
        "    \"AI Engineer\": [\n",
        "        \"What is overfitting and how do you prevent it?\",\n",
        "        \"When would you use a convolutional neural network?\",\n",
        "        \"How does gradient descent work?\"\n",
        "    ],\n",
        "    \"Cybersecurity Analyst\": [\n",
        "        \"What is SQL injection and how do you prevent it?\",\n",
        "        \"What are the core components of zero-trust security?\",\n",
        "        \"Describe the role of firewalls in network security.\"\n",
        "    ],\n",
        "    \"Cloud Architect\": [\n",
        "        \"What are the benefits of using infrastructure as code?\",\n",
        "        \"How would you design a highly available system on AWS?\",\n",
        "        \"What are the differences between IaaS and PaaS?\"\n",
        "    ],\n",
        "    \"DevOps Engineer\": [\n",
        "        \"What's the purpose of containerization?\",\n",
        "        \"How would you handle a failing CI/CD pipeline?\",\n",
        "        \"Explain blue-green deployment.\"\n",
        "    ],\n",
        "    \"Software Engineer\": [\n",
        "        \"What are SOLID principles in software design?\",\n",
        "        \"What is the difference between composition and inheritance?\",\n",
        "        \"Explain the concept of dependency injection.\"\n",
        "    ],\n",
        "    \"UX Developer\": [\n",
        "        \"How do you measure the usability of a design?\",\n",
        "        \"What is the role of accessibility in UX?\",\n",
        "        \"How do you handle conflicting user feedback?\"\n",
        "    ],\n",
        "    \"Product Manager\": [\n",
        "        \"How do you prioritize features in a roadmap?\",\n",
        "        \"Explain how you would handle scope creep.\",\n",
        "        \"Describe a time you dealt with conflicting stakeholder needs.\"\n",
        "    ],\n",
        "    \"Data Scientist\": [\n",
        "        \"What is the difference between classification and regression?\",\n",
        "        \"How do you handle missing data?\",\n",
        "        \"Explain the bias-variance tradeoff.\"\n",
        "    ]\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "generation-process"
      },
      "source": [
        "## 3. Generate Interview Conversations\n",
        "\n",
        "This section creates 50 unique interview conversations per role by:\n",
        "1. Selecting random greetings, questions, and responses\n",
        "2. Formatting them into prompt-completion pairs\n",
        "3. Storing in a list of dictionaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "generate-conversations"
      },
      "outputs": [],
      "source": [
        "conversations = []\n",
        "\n",
        "for role in roles:\n",
        "    for i in range(50):\n",
       
        "        greeting = random.choice(greetings).format(role=role)\n",
        "        question = random.choice(sample_questions[role])\n",
        "        followup = random.choice(follow_ups)\n",
        "        feedback = random.choice(feedbacks)\n",
        "        closing = random.choice(closings)\n",
        "\n",
       
        "        prompt = f\"Human: Hi\\nAI: {greeting}\\nHuman: Yes\\nAI: First question: {question}\"\n",
        "        completion = f\"Human: [user answer]\\nAI: {followup}\\nHuman: [follow-up response]\\nAI: {feedback}\\nAI: {closing}\"\n",
        "\n",
        
        "        conversations.append({\n",
        "            \"prompt\": prompt,\n",
        "            \"completion\": completion\n",
        "        })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "save-data"
      },
      "source": [
        "## 4. Save Dataset to File\n",
        "\n",
        "We'll save the generated conversations in JSONL format (one JSON object per line) which is ideal for training AI models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "save-dataset"
      },
      "outputs": [],
      "source": [
        "file_path = \"/tmp/interviewer_dataset_500.jsonl\"\n",
        "\n",
        "with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    for convo in conversations:\n",
        "        json.dump(convo, f)\n",
        "        f.write(\"\\n\") \n",
        "\n",
        "print(f\"Dataset successfully saved to {file_path}\")\n",
        "print(f\"Total conversations generated: {len(conversations)}\")"
      ]
    },
    }
  ]
}
